{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import varseek as vk\n",
    "import os\n",
    "# from tqdm import tqdm\n",
    "# tqdm.pandas()\n",
    "\n",
    "varseek_directory = os.path.dirname(os.path.abspath(\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutant_sequencing_depth = 256\n",
    "wt_sequencing_depth = 0\n",
    "condition = ['variant_type:equal=substitution']\n",
    "\n",
    "number_of_variants_to_sample_per_condition = 10_000\n",
    "read_length = 150\n",
    "strand = None  # None for strand-agnostic (randomly-selected), \"f\" for forward, \"r\" for reverse, \"both\" for both - make sure this matches the reference genome (vk build command) - strand = True -> \"f\" or \"r\" here; strand = False -> None or \"both\" here - note that the strand is randomly selected per *transcript*, such that all drawn reads will come from the same strand no matter what\n",
    "add_noise_sequencing_error=True\n",
    "add_noise_base_quality=False\n",
    "error_rate=0.0001  # only if add_noise_sequencing_error=True\n",
    "error_distribution=(0.85, 0.1, 0.05)  # sub, del, ins  # only if add_noise_sequencing_error=True\n",
    "max_errors=float(\"inf\")  # only if add_noise_sequencing_error=True\n",
    "seq_id_column=\"seq_ID\"\n",
    "var_column=\"mutation_cdna\"\n",
    "threads = 16\n",
    "\n",
    "k = 51\n",
    "w = 47\n",
    "\n",
    "# Paths\n",
    "vk_ref_out_dir = os.path.join(varseek_directory, \"data\", \"vk_ref_out\")\n",
    "reference_out_dir = os.path.join(varseek_directory, \"data\", \"reference\")\n",
    "sequences = os.path.join(reference_out_dir, \"ensembl_grch37_release93\", \"Homo_sapiens.GRCh37.cdna.all.fa\")\n",
    "reference_genome_fasta = os.path.join(reference_out_dir, \"ensembl_grch37_release93\", \"Homo_sapiens.GRCh37.dna.primary_assembly.fa\")\n",
    "out_dir_notebook = os.path.join(varseek_directory, \"data\", \"synthetic_reads_test_easy\")  #!!! change for each run\n",
    "read_fq_path = os.path.join(out_dir_notebook, \"synthetic_reads.fq\")\n",
    "\n",
    "mutation_metadata_df = os.path.join(vk_ref_out_dir, \"variants_updated_exploded_filtered.csv\")\n",
    "read_df_out = f\"{out_dir_notebook}/synthetic_reads.csv\"\n",
    "mutation_metadata_df_out = f\"{out_dir_notebook}/mutation_metadata_df_updated_vk_info_exploded_with_synthetic_read_info.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmrich/Desktop/varseek/varseek/varseek_sim.py:305: DtypeWarning: Columns (12,13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  variants = pd.read_csv(variants)\n",
      "12:15:06 - INFO - cannot find mutant sequence read parent\n",
      "12:15:06 - INFO - running varseek build\n",
      "12:15:06 - WARNING - If running a workflow with vk ref or kb ref, k should be an odd number between 1 and 63. Got k=147.\n",
      "12:15:06 - INFO - Using COSMIC email from COSMIC_EMAIL environment variable: jmrich@caltech.edu\n",
      "12:15:06 - INFO - Using COSMIC password from COSMIC_PASSWORD environment variable\n",
      "12:15:54 - INFO - Using var_id_column 'header' as the variant header column.\n",
      "12:20:56 - INFO - Removed 204 variant-containing reference sequences with length less than 150...\n",
      "12:20:56 - WARNING - \n",
      "        5372870 variants correctly recorded (100.00%)\n",
      "        204 variants removed (0.00%)\n",
      "          0 variants missing seq_id or var_column (0.000%)\n",
      "          0 entries removed due to having a duplicate entry (0.000%)\n",
      "          0 variants with seq_ID not found in sequences (0.000%)\n",
      "          0 intronic variants found (0.000%)\n",
      "          0 posttranslational region variants found (0.000%)\n",
      "          0 unknown variants found (0.000%)\n",
      "          0 variants with uncertain mutation found (0.000%)\n",
      "          0 variants with ambiguous position found (0.000%)\n",
      "          0 variants with incorrect wildtype base found (0.000%)\n",
      "          0 variants with indices outside of the sequence length found (0.000%)\n",
      "          204 variants with fragment length < min_seq_len removed (0.004%)\n",
      "        \n",
      "12:21:53 - INFO - Saving dataframe with updated variant info...\n",
      "12:21:53 - WARNING - File size can be very large if the number of variants is large.\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(read_fq_path):\n",
    "    simulated_df_dict = vk.sim(\n",
    "        variants=mutation_metadata_df,\n",
    "        number_of_variants_to_sample=number_of_variants_to_sample_per_condition,\n",
    "        strand=strand,\n",
    "        number_of_reads_per_variant_alt=mutant_sequencing_depth,\n",
    "        number_of_reads_per_variant_ref=wt_sequencing_depth,\n",
    "        k=k,\n",
    "        w=w,\n",
    "        read_length=read_length,\n",
    "        seed=None,  # no need to pass in since it's set globally\n",
    "        add_noise_sequencing_error=add_noise_sequencing_error,\n",
    "        error_rate=error_rate,\n",
    "        error_distribution=error_distribution,\n",
    "        max_errors=max_errors,\n",
    "        with_replacement=False,  # set to True if wanting to have some reads that might be identical\n",
    "        sequences=sequences,\n",
    "        seq_id_column=seq_id_column,\n",
    "        var_column=var_column,\n",
    "        var_id_column=\"header\",\n",
    "        variant_type_column=\"vcrs_variant_type\",\n",
    "        reference_out_dir=reference_out_dir,\n",
    "        filters=condition,\n",
    "        out=out_dir_notebook,\n",
    "        reads_fastq_out=read_fq_path,\n",
    "        reads_csv_out=read_df_out,\n",
    "        variants_updated_csv_out=mutation_metadata_df_out,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**number_variants = 10_000**\n",
    "\n",
    "number_variants x mutant_sequencing_depth = number_of_reads\n",
    "10_000 x 256 = 2_560_000\n",
    "\n",
    "number_of_reads + 1 (header row) = total_df_lines\n",
    "2_560_000 + 1 = 2_560_001\n",
    "\n",
    "number_of_reads x 4 (4 lines per read) = total_fastq_lines\n",
    "2_560_000 x 4 = 10_240_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2560001 /home/jmrich/Desktop/RLSRWP_2025/data/synthetic_reads_test_easy/synthetic_reads.csv\n",
      "10240000 /home/jmrich/Desktop/RLSRWP_2025/data/synthetic_reads_test_easy/synthetic_reads.fq\n"
     ]
    }
   ],
   "source": [
    "!wc -l {read_df_out}\n",
    "!wc -l {read_fq_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Haplotypecaller, same strand\n",
      "Number of reads in STAR BAM (out of 2560000)\n",
      "2590420\n",
      "Number of variants in unfiltered VCF (out of 10000)\n",
      "109\n",
      "Number of variants in filtered VCF (out of 10000)\n",
      "114\n"
     ]
    }
   ],
   "source": [
    "print(\"Haplotypecaller, same strand\")\n",
    "# !python scripts/run_gatk_haplotypecaller_for_benchmarking.py --synthetic_read_fastq /home/jmrich/Desktop/RLSRWP_2025/data/synthetic_reads_test_easy/synthetic_reads.fq --skip_accuracy_analysis --out /home/jmrich/Desktop/RLSRWP_2025/data/synthetic_reads_test_easy/GATK/haplotypecaller --reference_genome_fasta /data/reference/ensembl_grch37_release93/Homo_sapiens.GRCh37.dna.primary_assembly.fa --reference_genome_gtf /data/reference/ensembl_grch37_release93/Homo_sapiens.GRCh37.87.gtf --star_genome_dir data/reference/ensembl_grch37_release93/star_reference --java /home/jmrich/opt/jdk-17.0.12+7/bin/java --picard_jar /home/jmrich/opt/picard.jar --threads 16 --genomes1000_vcf /data/reference/ensembl_grch37_release93/1000GENOMES-phase_3.vcf --disable_tool_default_read_filters --tmp_dir /data/tmp2\n",
    "\n",
    "print(f\"Number of reads in STAR BAM (out of {number_of_variants_to_sample_per_condition * mutant_sequencing_depth})\")\n",
    "!samtools view -c -F 4 /home/jmrich/Desktop/RLSRWP_2025/data/synthetic_reads_test_easy/GATK/haplotypecaller/alignment/sample_Aligned.sortedByCoord.out.bam\n",
    "\n",
    "print(f\"Number of variants in unfiltered VCF (out of {number_of_variants_to_sample_per_condition})\")\n",
    "!zcat /home/jmrich/Desktop/RLSRWP_2025/data/synthetic_reads_test_easy/GATK/haplotypecaller/vcfs/haplotypecaller/haplotypecaller_output_unfiltered.g.vcf.gz | wc -l\n",
    "\n",
    "print(f\"Number of variants in filtered VCF (out of {number_of_variants_to_sample_per_condition})\")\n",
    "!zcat /home/jmrich/Desktop/RLSRWP_2025/data/synthetic_reads_test_easy/GATK/haplotypecaller/vcfs/haplotypecaller/haplotypecaller_output_filtered_applied.vcf.gz | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mutect2, same strand\n",
      "Number of reads in STAR BAM (out of 2560000)\n",
      "2590420\n",
      "Number of variants in unfiltered VCF (out of 10000)\n",
      "129\n",
      "Number of variants in filtered VCF (out of 10000)\n",
      "157\n"
     ]
    }
   ],
   "source": [
    "print(\"Mutect2, same strand\")\n",
    "# !python scripts/run_gatk_mutect2_for_benchmarking.py --synthetic_read_fastq /home/jmrich/Desktop/RLSRWP_2025/data/synthetic_reads_test_easy/synthetic_reads.fq --skip_accuracy_analysis --out /home/jmrich/Desktop/RLSRWP_2025/data/synthetic_reads_test_easy/GATK/mutect2 --reference_genome_fasta /data/reference/ensembl_grch37_release93/Homo_sapiens.GRCh37.dna.primary_assembly.fa --reference_genome_gtf /data/reference/ensembl_grch37_release93/Homo_sapiens.GRCh37.87.gtf --star_genome_dir data/reference/ensembl_grch37_release93/star_reference --java /home/jmrich/opt/jdk-17.0.12+7/bin/java --picard_jar /home/jmrich/opt/picard.jar --threads 16 --genomes1000_vcf /data/reference/ensembl_grch37_release93/1000GENOMES-phase_3.vcf --disable_tool_default_read_filters --tmp_dir /data/tmp3\n",
    "\n",
    "print(f\"Number of reads in STAR BAM (out of {number_of_variants_to_sample_per_condition * mutant_sequencing_depth})\")\n",
    "!samtools view -c -F 4 /home/jmrich/Desktop/RLSRWP_2025/data/synthetic_reads_test_easy/GATK/mutect2/alignment/sample_Aligned.sortedByCoord.out.bam\n",
    "\n",
    "print(f\"Number of variants in unfiltered VCF (out of {number_of_variants_to_sample_per_condition})\")\n",
    "!zcat /home/jmrich/Desktop/RLSRWP_2025/data/synthetic_reads_test_easy/GATK/mutect2/vcfs/mutect2/mutect2_output_unfiltered.g.vcf.gz | wc -l\n",
    "\n",
    "print(f\"Number of variants in filtered VCF (out of {number_of_variants_to_sample_per_condition})\")\n",
    "!zcat /home/jmrich/Desktop/RLSRWP_2025/data/synthetic_reads_test_easy/GATK/mutect2/vcfs/mutect2/mutect2_output_filtered_applied.vcf.gz | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmrich/Desktop/varseek/varseek/varseek_sim.py:305: DtypeWarning: Columns (12,13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  variants = pd.read_csv(variants)\n",
      "13:36:44 - INFO - cannot find mutant sequence read parent\n",
      "/home/jmrich/Desktop/varseek/varseek/varseek_sim.py:361: DtypeWarning: Columns (13,14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  sim_data_df = pd.read_csv(update_df_out)\n",
      "13:40:06 - INFO - Initial variant report\n",
      "13:40:06 - INFO - Number of total variants: 5373074; VCRSs: 5373074; unique variants: 5373074; merged variants: 0\n",
      "\n",
      "13:40:06 - INFO - variant_type equal substitution\n",
      "13:40:10 - INFO - Number of total variants: 5143917 (229157 filtered); VCRSs: 5143917 (229157 filtered); unique variants: 5143917 (229157 filtered); merged variants: 0 (0 filtered)\n",
      "\n",
      "13:40:10 - INFO - mutant_sequence_read_parent is_not_null None\n",
      "13:40:16 - INFO - Number of total variants: 5143740 (177 filtered); VCRSs: 5143740 (177 filtered); unique variants: 5143740 (177 filtered); merged variants: 0 (0 filtered)\n",
      "\n",
      "13:40:16 - INFO - wt_sequence_read_parent is_not_null None\n",
      "13:40:23 - INFO - Number of total variants: 5143740 (0 filtered); VCRSs: 5143740 (0 filtered); unique variants: 5143740 (0 filtered); merged variants: 0 (0 filtered)\n",
      "\n",
      "13:40:23 - INFO - mutant_sequence_read_parent_length greater_or_equal 150.0\n",
      "13:40:28 - INFO - Number of total variants: 5143740 (0 filtered); VCRSs: 5143740 (0 filtered); unique variants: 5143740 (0 filtered); merged variants: 0 (0 filtered)\n",
      "\n",
      "13:40:28 - INFO - Total variants filtered: 229334; total VCRSs filtered: 229334; unique variants filtered: 229334; merged variants filtered: 0\n",
      "13:40:28 - INFO - Total runtime for vk filter: 0m, 25.21s\n",
      "13:40:29 - WARNING - variant_type_column vcrs_variant_type not in dataframe\n",
      "13:40:29 - INFO - Simulating 2560000 reads - 10000 variants, with 0 ref reads per variant and 256 alt reads per variant\n",
      "Looping through variants to simulate reads: 100%|██████████| 10000/10000 [01:14<00:00, 134.43variants/s]\n",
      "13:41:47 - INFO - Wrote 2560000 variants to /home/jmrich/Desktop/RLSRWP_2025/data/synthetic_reads_test_easy/synthetic_reads_mixed_strands.fq\n",
      "13:46:42 - INFO - Total runtime for vk sim: 11m, 28.00s\n"
     ]
    }
   ],
   "source": [
    "strand = \"random\"\n",
    "read_fq_path_mixed_strands = os.path.join(out_dir_notebook, \"synthetic_reads_mixed_strands.fq\")\n",
    "read_df_out = os.path.join(out_dir_notebook, \"synthetic_reads_mixed_strands.csv\")\n",
    "mutation_metadata_df_out = os.path.join(out_dir_notebook, \"mutation_metadata_df_updated_vk_info_exploded_with_synthetic_read_info_mixed_strands.csv\")\n",
    "\n",
    "if not os.path.exists(read_fq_path_mixed_strands):\n",
    "    simulated_df_dict = vk.sim(\n",
    "        variants=mutation_metadata_df,\n",
    "        number_of_variants_to_sample=number_of_variants_to_sample_per_condition,\n",
    "        strand=strand,\n",
    "        number_of_reads_per_variant_alt=mutant_sequencing_depth,\n",
    "        number_of_reads_per_variant_ref=wt_sequencing_depth,\n",
    "        k=k,\n",
    "        w=w,\n",
    "        read_length=read_length,\n",
    "        seed=None,  # no need to pass in since it's set globally\n",
    "        add_noise_sequencing_error=add_noise_sequencing_error,\n",
    "        error_rate=error_rate,\n",
    "        error_distribution=error_distribution,\n",
    "        max_errors=max_errors,\n",
    "        with_replacement=False,  # set to True if wanting to have some reads that might be identical\n",
    "        sequences=sequences,\n",
    "        seq_id_column=seq_id_column,\n",
    "        var_column=var_column,\n",
    "        var_id_column=\"header\",\n",
    "        variant_type_column=\"vcrs_variant_type\",\n",
    "        reference_out_dir=reference_out_dir,\n",
    "        filters=condition,\n",
    "        out=out_dir_notebook,\n",
    "        reads_fastq_out=read_fq_path_mixed_strands,\n",
    "        reads_csv_out=read_df_out,\n",
    "        variants_updated_csv_out=mutation_metadata_df_out,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Haplotypecaller, mixed strands\n",
      "Number of reads in STAR BAM (out of 2560000)\n",
      "2589084\n",
      "Number of variants in unfiltered VCF (out of 10000)\n",
      "9961\n",
      "Number of variants in filtered VCF (out of 10000)\n",
      "9936\n"
     ]
    }
   ],
   "source": [
    "print(\"Haplotypecaller, mixed strands\")\n",
    "# !python scripts/run_gatk_haplotypecaller_for_benchmarking.py --synthetic_read_fastq /home/jmrich/Desktop/RLSRWP_2025/data/synthetic_reads_test_easy/synthetic_reads_mixed_strands.fq --skip_accuracy_analysis --out /home/jmrich/Desktop/RLSRWP_2025/data/synthetic_reads_test_easy/GATK_mixed_strands/haplotypecaller --reference_genome_fasta /data/reference/ensembl_grch37_release93/Homo_sapiens.GRCh37.dna.primary_assembly.fa --reference_genome_gtf /data/reference/ensembl_grch37_release93/Homo_sapiens.GRCh37.87.gtf --star_genome_dir data/reference/ensembl_grch37_release93/star_reference --java /home/jmrich/opt/jdk-17.0.12+7/bin/java --picard_jar /home/jmrich/opt/picard.jar --threads 16 --genomes1000_vcf /data/reference/ensembl_grch37_release93/1000GENOMES-phase_3.vcf --disable_tool_default_read_filters --tmp_dir /data/tmp2\n",
    "\n",
    "print(f\"Number of reads in STAR BAM (out of {number_of_variants_to_sample_per_condition * mutant_sequencing_depth})\")\n",
    "!samtools view -c -F 4 /home/jmrich/Desktop/RLSRWP_2025/data/synthetic_reads_test_easy/GATK_mixed_strands/haplotypecaller/alignment/sample_Aligned.sortedByCoord.out.bam\n",
    "\n",
    "print(f\"Number of variants in unfiltered VCF (out of {number_of_variants_to_sample_per_condition})\")\n",
    "!zcat /home/jmrich/Desktop/RLSRWP_2025/data/synthetic_reads_test_easy/GATK_mixed_strands/haplotypecaller/vcfs/haplotypecaller/haplotypecaller_output_unfiltered.g.vcf.gz | wc -l\n",
    "\n",
    "print(f\"Number of variants in filtered VCF (out of {number_of_variants_to_sample_per_condition})\")\n",
    "!zcat /home/jmrich/Desktop/RLSRWP_2025/data/synthetic_reads_test_easy/GATK_mixed_strands/haplotypecaller/vcfs/haplotypecaller/haplotypecaller_output_filtered_applied.vcf.gz | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mutect2, mixed strands\n",
      "Number of reads in STAR BAM (out of 2560000)\n",
      "2589084\n",
      "Number of variants in unfiltered VCF (out of 10000)\n",
      "9986\n",
      "Number of variants in filtered VCF (out of 10000)\n",
      "7791\n"
     ]
    }
   ],
   "source": [
    "print(\"Mutect2, mixed strands\")\n",
    "# !python scripts/run_gatk_mutect2_for_benchmarking.py --synthetic_read_fastq /home/jmrich/Desktop/RLSRWP_2025/data/synthetic_reads_test_easy/synthetic_reads_mixed_strands.fq --skip_accuracy_analysis --out /home/jmrich/Desktop/RLSRWP_2025/data/synthetic_reads_test_easy/GATK_mixed_strands/mutect2 --reference_genome_fasta /data/reference/ensembl_grch37_release93/Homo_sapiens.GRCh37.dna.primary_assembly.fa --reference_genome_gtf /data/reference/ensembl_grch37_release93/Homo_sapiens.GRCh37.87.gtf --star_genome_dir data/reference/ensembl_grch37_release93/star_reference --java /home/jmrich/opt/jdk-17.0.12+7/bin/java --picard_jar /home/jmrich/opt/picard.jar --threads 16 --genomes1000_vcf /data/reference/ensembl_grch37_release93/1000GENOMES-phase_3.vcf --disable_tool_default_read_filters --tmp_dir /data/tmp3\n",
    "\n",
    "print(f\"Number of reads in STAR BAM (out of {number_of_variants_to_sample_per_condition * mutant_sequencing_depth})\")\n",
    "!samtools view -c -F 4 /home/jmrich/Desktop/RLSRWP_2025/data/synthetic_reads_test_easy/GATK_mixed_strands/mutect2/alignment/sample_Aligned.sortedByCoord.out.bam\n",
    "\n",
    "print(f\"Number of variants in unfiltered VCF (out of {number_of_variants_to_sample_per_condition})\")\n",
    "!zcat /home/jmrich/Desktop/RLSRWP_2025/data/synthetic_reads_test_easy/GATK_mixed_strands/mutect2/vcfs/mutect2/mutect2_output_unfiltered.g.vcf.gz | wc -l\n",
    "\n",
    "print(f\"Number of variants in filtered VCF (out of {number_of_variants_to_sample_per_condition})\")\n",
    "!zcat /home/jmrich/Desktop/RLSRWP_2025/data/synthetic_reads_test_easy/GATK_mixed_strands/mutect2/vcfs/mutect2/mutect2_output_filtered_applied.vcf.gz | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155780\n",
      "127822\n"
     ]
    }
   ],
   "source": [
    "!zcat /home/jmrich/Desktop/RLSRWP_2025/data/variant_simulation_alternative_tools/vcfs/haplotypecaller/haplotypecaller_output_unfiltered.g.vcf.gz | wc -l\n",
    "!zcat /home/jmrich/Desktop/RLSRWP_2025/data/variant_simulation_alternative_tools/vcfs/haplotypecaller/haplotypecaller_output_filtered_applied.vcf.gz | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unrelated stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3699833/2965374728.py:12: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  cosmic_df_with_vcf_info_df = pd.read_csv(cosmic_df_with_vcf_info_path)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import pysam\n",
    "import varseek as vk\n",
    "\n",
    "unique_mcrs_df_path = \"/home/jmrich/Desktop/RLSRWP_2025/data/simulated_data_output/unique_mcrs_df.csv\"\n",
    "unique_mcrs_df_original_path = \"/home/jmrich/Desktop/RLSRWP_2025/data/simulated_data_output/unique_mcrs_df_original.csv\"\n",
    "cosmic_df_with_vcf_info_path = \"/home/jmrich/Desktop/RLSRWP_2025/data/reference/cosmic/CancerMutationCensus_AllData_Tsv_v101_GRCh37/CancerMutationCensus_AllData_v101_GRCh37_vcf_info_for_fig2.csv\"\n",
    "\n",
    "unique_mcrs_df = pd.read_csv(unique_mcrs_df_path, usecols=[\"vcrs_header\"])\n",
    "cosmic_df_with_vcf_info_df = pd.read_csv(cosmic_df_with_vcf_info_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- explode unique_mcrs_df['vcrs_header'] by semicolon\n",
    "- left merge in cosmic_df_with_vcf_info_df into unique_mcrs_df by ID for cosmic_df_with_vcf_info_df and vcrs_header for unique_mcrs_df\n",
    "- groupby unique_mcrs_df with column vcrs_id, putting values in a list for CHROM, POS, REF, ALT and taking the first value for vcrs_header_original\n",
    "- take the set of each of CHROM, POS, REF, ALT\n",
    "- filter out rows with length of any of these sets larger than 1\n",
    "- take the first element of each set as the new entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# give each row in unique_mcrs_df a unique ID\n",
    "unique_mcrs_df['vcrs_id'] = ['vcrs_' + str(i) for i in range(1, len(unique_mcrs_df) + 1)]\n",
    "\n",
    "# Step 1: Explode `vcrs_header` by semicolon\n",
    "unique_mcrs_df['vcrs_header_original'] = unique_mcrs_df['vcrs_header']\n",
    "unique_mcrs_df = unique_mcrs_df.assign(\n",
    "    vcrs_header=unique_mcrs_df['vcrs_header'].str.split(';')\n",
    ").explode('vcrs_header')\n",
    "\n",
    "# Step 2: Left merge with cosmic_df_with_vcf_info_df on vcrs_header ↔ ID\n",
    "merged_df = unique_mcrs_df.merge(\n",
    "    cosmic_df_with_vcf_info_df,\n",
    "    how='left',\n",
    "    left_on='vcrs_header',\n",
    "    right_on='ID'\n",
    ")\n",
    "\n",
    "# Step 3: Group by vcrs_id, aggregate lists and take first original header\n",
    "grouped = merged_df.groupby('vcrs_id').agg({\n",
    "    'CHROM': lambda x: list(x.dropna()),\n",
    "    'POS': lambda x: list(x.dropna()),\n",
    "    'REF': lambda x: list(x.dropna()),\n",
    "    'ALT': lambda x: list(x.dropna()),\n",
    "    'vcrs_header_original': 'first'\n",
    "}).reset_index()\n",
    "\n",
    "# Step 4: Convert each to a set\n",
    "grouped['CHROM_set'] = grouped['CHROM'].apply(set)\n",
    "grouped['POS_set'] = grouped['POS'].apply(set)\n",
    "grouped['REF_set'] = grouped['REF'].apply(set)\n",
    "grouped['ALT_set'] = grouped['ALT'].apply(set)\n",
    "\n",
    "# Step 5: Filter rows where any set has length > 1\n",
    "filtered = grouped[\n",
    "    (grouped['CHROM_set'].apply(len) == 1) &\n",
    "    (grouped['POS_set'].apply(len) == 1) &\n",
    "    (grouped['REF_set'].apply(len) == 1) &\n",
    "    (grouped['ALT_set'].apply(len) == 1)\n",
    "].copy()\n",
    "\n",
    "# Step 6: Take first (only) element of each set\n",
    "filtered['CHROM'] = filtered['CHROM_set'].apply(lambda s: next(iter(s)))\n",
    "filtered['POS']   = filtered['POS_set'].apply(lambda s: next(iter(s)))\n",
    "filtered['REF']   = filtered['REF_set'].apply(lambda s: next(iter(s)))\n",
    "filtered['ALT']   = filtered['ALT_set'].apply(lambda s: next(iter(s)))\n",
    "\n",
    "filtered['POS'] = filtered['POS'].astype(int)\n",
    "\n",
    "# Optional: Drop the intermediate set columns\n",
    "filtered = filtered.drop(columns=['CHROM_set', 'POS_set', 'REF_set', 'ALT_set'])\n",
    "# filtered = filtered.rename(columns={'vcrs_header_original': 'ID'})\n",
    "filtered = filtered.rename(columns={'vcrs_id': 'ID'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81108\n",
      "25807\n"
     ]
    }
   ],
   "source": [
    "print((unique_mcrs_df['vcrs_header_original'].str.contains(';')).sum())  # number with semicolon\n",
    "print(len(grouped) - len(filtered))  # number with different VCF info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosmic_simulated_vcf_file_name = \"synthetic_cosmic_simulated_reads.vcf.gz\"\n",
    "cosmic_simulated_vcf = os.path.join(\"/data\", \"simulated_data_output\", cosmic_simulated_vcf_file_name)\n",
    "reference_genome_fasta = \"/data/reference/ensembl_grch37_release93/Homo_sapiens.GRCh37.dna.primary_assembly.fa\"\n",
    "reference_genome_fasta_index = reference_genome_fasta.replace(\".fa\", \".fa.fai\")\n",
    "\n",
    "if not os.path.isfile(cosmic_simulated_vcf):\n",
    "    unsorted_vcf = cosmic_simulated_vcf.replace(\".vcf.gz\", \"_unsorted.vcf\")\n",
    "    vk.utils.write_to_vcf(filtered, output_file = unsorted_vcf)\n",
    "\n",
    "    # add FORMAT/SAMPLE\n",
    "    output_vcf_path = cosmic_simulated_vcf.replace(\".vcf\", \"_tmp.vcf\")\n",
    "\n",
    "    # Open original VCF\n",
    "    in_vcf = pysam.VariantFile(unsorted_vcf, \"r\")\n",
    "\n",
    "    # Clone header and add FORMAT and sample\n",
    "    new_header = in_vcf.header.copy()\n",
    "\n",
    "    # Add missing contigs to new_header\n",
    "    for rec in in_vcf.fetch():\n",
    "        contig = rec.contig\n",
    "        if contig not in new_header.contigs:\n",
    "            new_header.contigs.add(contig, length=1_000_000)  # Dummy length\n",
    "\n",
    "    # Reset the iterator\n",
    "    in_vcf.close()\n",
    "    in_vcf = pysam.VariantFile(unsorted_vcf, \"r\")\n",
    "\n",
    "    new_header.formats.add(\"GT\", 1, \"String\", \"Genotype\")\n",
    "    new_header.add_sample(\"synthetic\")\n",
    "\n",
    "    # Open output VCF\n",
    "    out_vcf = pysam.VariantFile(output_vcf_path, \"w\", header=new_header)\n",
    "\n",
    "    # Write each record with dummy genotype\n",
    "    for rec in in_vcf:\n",
    "        # Create a new record to match the new header\n",
    "        new_rec = out_vcf.new_record(contig=rec.contig,\n",
    "                                    start=rec.start,\n",
    "                                    stop=rec.stop,\n",
    "                                    id=rec.id,\n",
    "                                    qual=rec.qual,\n",
    "                                    filter=rec.filter.keys(),\n",
    "                                    alleles=rec.alleles,\n",
    "                                    info=dict(rec.info))\n",
    "\n",
    "        new_rec.samples[\"synthetic\"][\"GT\"] = (0, 1)  # Set genotype\n",
    "        out_vcf.write(new_rec)\n",
    "\n",
    "    # Close files\n",
    "    in_vcf.close()\n",
    "    out_vcf.close()\n",
    "\n",
    "    output_tmp2 = output_vcf_path.replace(\"_tmp.vcf\", \"_tmp2.vcf.gz\")\n",
    "    !bcftools sort -O z -o {output_tmp2} {output_vcf_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "happy_base_dir = \"/home/jmrich/Desktop/RLSRWP_2025\"\n",
    "happy_output_dir_name = \"happy\"\n",
    "\n",
    "os.makedirs(os.path.join(happy_base_dir, happy_output_dir_name), exist_ok=True)\n",
    "cosmic_simulated_vcf_in_happy_base_dir = os.path.join(happy_base_dir, happy_output_dir_name, cosmic_simulated_vcf_file_name)\n",
    "reference_genome_fasta_in_happy_base_dir = os.path.join(happy_base_dir, happy_output_dir_name, \"Homo_sapiens.GRCh37.dna.primary_assembly.fa\")\n",
    "reference_genome_fasta_index_in_happy_base_dir = reference_genome_fasta_in_happy_base_dir.replace(\".fa\", \".fa.fai\")\n",
    "if not os.path.exists(cosmic_simulated_vcf_in_happy_base_dir):\n",
    "    shutil.copyfile(cosmic_simulated_vcf, cosmic_simulated_vcf_in_happy_base_dir)\n",
    "if not os.path.exists(reference_genome_fasta_in_happy_base_dir):\n",
    "    shutil.copyfile(reference_genome_fasta, reference_genome_fasta_in_happy_base_dir)\n",
    "    shutil.copyfile(reference_genome_fasta_index, reference_genome_fasta_index_in_happy_base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sudo docker run --rm -it -v /home/jmrich/Desktop/RLSRWP_2025:/data mgibio/hap.py:v0.3.12 /opt/hap.py/bin/hap.py -r /data/happy/Homo_sapiens.GRCh37.dna.primary_assembly.fa -o /data/happy/gatk_haplotypecaller/happy /data/happy/synthetic_cosmic_simulated_reads.vcf /data/happy/haplotypecaller_output_unfiltered.g.vcf.gz\n"
     ]
    }
   ],
   "source": [
    "alternative_tool = \"gatk_haplotypecaller\"\n",
    "alternative_tool_vcf = \"/home/jmrich/Desktop/RLSRWP_2025/data/variant_simulation_alternative_tools3/vcfs/haplotypecaller/haplotypecaller_output_unfiltered.g.vcf.gz\"\n",
    "alternative_tool_vcf_file_name = \"haplotypecaller_output_unfiltered.g.vcf.gz\"\n",
    "\n",
    "alternative_tool_vcf_in_happy_base_dir = os.path.join(happy_base_dir, happy_output_dir_name, alternative_tool_vcf_file_name)\n",
    "if not os.path.exists(alternative_tool_vcf_in_happy_base_dir):\n",
    "    shutil.copyfile(alternative_tool_vcf, alternative_tool_vcf_in_happy_base_dir)\n",
    "\n",
    "happy_out_dir = os.path.join(happy_base_dir, happy_output_dir_name, alternative_tool)\n",
    "os.makedirs(happy_out_dir, exist_ok=True)\n",
    "if not os.listdir(happy_out_dir):\n",
    "    print(f\"sudo docker run --rm -it -v {happy_base_dir}:/data mgibio/hap.py:v0.3.12 /opt/hap.py/bin/hap.py -r /data/{happy_output_dir_name}/Homo_sapiens.GRCh37.dna.primary_assembly.fa -o /data/{happy_output_dir_name}/{alternative_tool}/happy /data/{happy_output_dir_name}/{cosmic_simulated_vcf_file_name} /data/{happy_output_dir_name}/{alternative_tool_vcf_file_name}\")\n",
    "    # !sudo docker run --rm -it -v {happy_base_dir}:/data mgibio/hap.py:v0.3.12 /opt/hap.py/bin/hap.py -r /data/{happy_output_dir_name}/{Homo_sapiens.GRCh37.dna.primary_assembly.fa} -o /data/{happy_output_dir_name}/{alternative_tool}/happy /data/{happy_output_dir_name}/{cosmic_simulated_vcf_file_name} /data/{happy_output_dir_name}/{alternative_tool_vcf_file_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_csv_path = os.path.join(happy_out_dir, \"happy.summary.csv\")\n",
    "summary_df = pd.read_csv(summary_csv_path)\n",
    "summary_df = summary_df.loc[summary_df[\"Filter\"] == \"ALL\"]\n",
    "\n",
    "# Sum total TP, FP, FN across all rows\n",
    "total_tp = summary_df[\"TRUTH.TP\"].sum()\n",
    "total_fp = summary_df[\"QUERY.FP\"].sum()\n",
    "total_fn = summary_df[\"TRUTH.FN\"].sum()\n",
    "\n",
    "# Store in dictionary\n",
    "results = {\n",
    "    \"TP\": int(total_tp),\n",
    "    \"FP\": int(total_fp),\n",
    "    \"FN\": int(total_fn),\n",
    "}\n",
    "\n",
    "# # Save to file\n",
    "# with open(\"happy_counts.txt\", \"w\") as f:\n",
    "#     for k, v in results.items():\n",
    "#         f.write(f\"{k}: {v}\\n\")\n",
    "\n",
    "# Also print if desired\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_mcrs_df = pd.read_csv(unique_mcrs_df_original_path)\n",
    "\n",
    "# Step 1: Load happy.vcf.gz (annotated VCF)\n",
    "happy_vcf = pysam.VariantFile(os.path.join(happy_out_dir, \"happy.vcf.gz\"))\n",
    "\n",
    "# Step 2: Load original VCF (with IDs)\n",
    "orig_vcf = pysam.VariantFile(cosmic_simulated_vcf)\n",
    "\n",
    "# Step 3: Build a lookup dictionary from original VCF\n",
    "orig_lookup = {}\n",
    "for rec in orig_vcf.fetch():\n",
    "    key = (rec.contig, rec.pos, rec.ref, tuple(rec.alts))\n",
    "    orig_lookup[key] = rec.id\n",
    "\n",
    "# Step 4: Collect IDs based on TP and FN\n",
    "detected_ids = set()\n",
    "undetected_ids = set()\n",
    "\n",
    "for rec in happy_vcf.fetch():\n",
    "    for sample in rec.samples.values():\n",
    "        bd = sample.get(\"BD\")\n",
    "        if bd in [\"TP\", \"FN\"]:\n",
    "            key = (rec.contig, rec.pos, rec.ref, tuple(rec.alts))\n",
    "            match_id = orig_lookup.get(key)\n",
    "            if match_id and bd == \"TP\":\n",
    "                detected_ids.add(match_id)\n",
    "            elif match_id and bd == \"FN\":\n",
    "                undetected_ids.add(match_id)\n",
    "\n",
    "\n",
    "# TP: in detected and in synthetic\n",
    "unique_mcrs_df['TP_gatk_haplotypecaller'] = (\n",
    "    unique_mcrs_df['vcrs_id'].isin(detected_ids) &\n",
    "    unique_mcrs_df['included_in_synthetic_reads_mutant']\n",
    ")\n",
    "\n",
    "# FN: not in detected but in synthetic\n",
    "unique_mcrs_df['FN_gatk_haplotypecaller'] = (\n",
    "    ~unique_mcrs_df['vcrs_id'].isin(detected_ids) &\n",
    "    unique_mcrs_df['included_in_synthetic_reads_mutant']\n",
    ")\n",
    "\n",
    "# FP: in detected but NOT in synthetic\n",
    "unique_mcrs_df['FP_gatk_haplotypecaller'] = (\n",
    "    unique_mcrs_df['vcrs_id'].isin(detected_ids) &\n",
    "    ~unique_mcrs_df['included_in_synthetic_reads_mutant']\n",
    ")\n",
    "\n",
    "# TN: not in undetected and NOT in synthetic\n",
    "unique_mcrs_df['TN_gatk_haplotypecaller'] = (\n",
    "    ~unique_mcrs_df['vcrs_id'].isin(undetected_ids) &\n",
    "    ~unique_mcrs_df['included_in_synthetic_reads_mutant']\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "varseek2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
